# -*- coding: utf-8 -*-
"""PC1_NLP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GwfPkoLkrjAyPEb2sUb7rKrb2U8p19I_
"""

import math
import collections
from typing import List, Tuple, Dict
import random
import numpy as np
import nltk
nltk.download('punkt')
from nltk.tokenize import word_tokenize

def leer_archivo(ruta):
    with open(ruta, 'r', encoding='utf-8') as file:
        return file.readlines()

ruta = 'infopankki.en-es.es'
archivo = leer_archivo(ruta)

def preprocesar_archivo(archivo, num_muestras=10000):
    documentos = []
    for muestra in random.sample(archivo, num_muestras):
        tokens = word_tokenize(muestra.lower())
        tokens = [token for token in tokens if token.isalpha()]
        documentos.append(tokens)
    return documentos

corpus_entrenamiento = preprocesar_archivo(archivo)
print(f"Tamaño del corpus de entrenamiento: {len(corpus_entrenamiento)}")

def construir_vocabulario(corpus: List[List[str]]) -> Dict[str, int]:
    vocabulario = {}
    for documento in corpus:
        for token in documento:
            if token not in vocabulario:
                vocabulario[token] = len(vocabulario)
    return vocabulario

vocabulario = construir_vocabulario(corpus_entrenamiento)
tam_vocabulario = len(vocabulario)
print(f"Tamaño del vocabulario: {tam_vocabulario}")

class ModeloNGrama:
    def __init__(self, n: int):
        self.n = n
        self.cuenta_ngrama = collections.Counter()
        self.cuenta_contexto = collections.Counter()
        self.vocabulario = set()
        self.total_ngrama = 0

    def entrenar(self, corpus: List[List[str]]):
        for documento in corpus:
            tokens = ['<s>'] * (self.n - 1) + documento + ['</s>']
            self.vocabulario.update(tokens)
            for i in range(len(tokens) - self.n + 1):
                ngrama = tuple(tokens[i:i + self.n])
                contexto = tuple(tokens[i:i + self.n - 1])
                self.cuenta_ngrama[ngrama] += 1
                self.cuenta_contexto[contexto] += 1
                self.total_ngrama += 1

    def obtener_prob_ngram(self, ngrama: Tuple[str, ...]) -> float:
        cuenta = self.cuenta_ngrama.get(ngrama, 0)
        contexto = ngrama[:-1]
        cuenta_contexto = self.cuenta_contexto.get(contexto, 0)
        if cuenta_contexto == 0:
            return 0.0
        else:
            return cuenta / cuenta_contexto

class ModeloInterpoladoNGrama:
    def __init__(self, lambdas: Tuple[float, float, float]):
        self.modelo_unigrama = ModeloNGrama(n=1)
        self.modelo_bigrama = ModeloNGrama(n=2)
        self.modelo_trigrama = ModeloNGrama(n=3)
        self.lambdas = lambdas
        self.n = 3

    def entrenar(self, corpus: List[List[str]]):
        self.modelo_unigrama.entrenar(corpus)
        self.modelo_bigrama.entrenar(corpus)
        self.modelo_trigrama.entrenar(corpus)

    def obtener_prob_interpolada(self, ngrama: Tuple[str, ...]) -> float:
        prob_unigrama = self.modelo_unigrama.obtener_prob_ngram(ngrama[-1:])
        prob_bigrama = self.modelo_bigrama.obtener_prob_ngram(ngrama[-2:])
        prob_trigrama = self.modelo_trigrama.obtener_prob_ngram(ngrama)
        return self.lambdas[0] * prob_trigrama + self.lambdas[1] * prob_bigrama + self.lambdas[2] * prob_unigrama


class ModeloBackoffNGrama:
    def __init__(self, alpha: float = 0.4):
        self.modelo_unigrama = ModeloNGrama(n=1)
        self.modelo_bigrama = ModeloNGrama(n=2)
        self.modelo_trigrama = ModeloNGrama(n=3)
        self.n = 3
        self.alpha = alpha

    def entrenar(self, corpus: List[List[str]]):
        self.modelo_unigrama.entrenar(corpus)
        self.modelo_bigrama.entrenar(corpus)
        self.modelo_trigrama.entrenar(corpus)

    def obtener_prob_ngram(self, ngrama: Tuple[str, ...]) -> float:
        cuenta_trigrama = self.modelo_trigrama.cuenta_ngrama.get(ngrama, 0)
        contexto_trigrama = ngrama[:-1]
        cuenta_contexto_trigrama = self.modelo_trigrama.cuenta_contexto.get(contexto_trigrama, 0)

        if cuenta_contexto_trigrama > 0:
            return cuenta_trigrama / cuenta_contexto_trigrama

        bigrama = ngrama[-2:]
        cuenta_bigrama = self.modelo_bigrama.cuenta_ngrama.get(bigrama, 0)
        contexto_bigrama = bigrama[:-1]
        cuenta_contexto_bigrama = self.modelo_bigrama.cuenta_contexto.get(contexto_bigrama, 0)

        if cuenta_contexto_bigrama > 0:
            return self.alpha * (cuenta_bigrama / cuenta_contexto_bigrama)

        unigrama = ngrama[-1:]
        cuenta_unigrama = self.modelo_unigrama.cuenta_ngrama.get(unigrama, 0)
        total_unigramas = sum(self.modelo_unigrama.cuenta_ngrama.values())

        if total_unigramas > 0:
            return self.alpha * (cuenta_unigrama / total_unigramas)

        return 1e-6

def calcular_perplejidad(modelo: ModeloNGrama, corpus: List[List[str]]) -> float:
    total_log_prob = 0.0
    total_tokens = 0
    for documento in corpus:
        tokens = ['<s>'] * (modelo.n - 1) + documento + ['</s>']
        for i in range(len(tokens) - modelo.n + 1):
            ngrama = tuple(tokens[i:i + modelo.n])
            prob = modelo.obtener_prob_ngram(ngrama)
            if prob > 0:
                log_prob = -math.log2(prob)
            else:
                log_prob = -math.log2(1e-6)
            total_log_prob += log_prob
            total_tokens += 1
    avg_log_prob = total_log_prob / total_tokens
    perplejidad = 2 ** avg_log_prob
    return perplejidad

modelo_unigrama = ModeloNGrama(n=1)
modelo_bigrama = ModeloNGrama(n=2)
modelo_trigrama = ModeloNGrama(n=3)

modelo_unigrama.entrenar(corpus_entrenamiento)
modelo_bigrama.entrenar(corpus_entrenamiento)
modelo_trigrama.entrenar(corpus_entrenamiento)

lambdas = (0.3, 0.4, 0.3)
modelo_interpolado = ModeloInterpoladoNGrama(lambdas)
modelo_interpolado.entrenar(corpus_entrenamiento)

modelo_backoff = ModeloBackoffNGrama()
modelo_backoff.entrenar(corpus_entrenamiento)

perplejidad_unigrama = calcular_perplejidad(modelo_unigrama, corpus_entrenamiento)
perplejidad_bigrama = calcular_perplejidad(modelo_bigrama, corpus_entrenamiento)
perplejidad_trigrama = calcular_perplejidad(modelo_trigrama, corpus_entrenamiento)

print(f"Perplejidad Unigrama: {perplejidad_unigrama:.4f}")
print(f"Perplejidad Bigrama: {perplejidad_bigrama:.4f}")
print(f"Perplejidad Trigrama: {perplejidad_trigrama:.4f}")

perplejidad_interpolada = calcular_perplejidad(modelo_interpolado.modelo_trigrama, corpus_entrenamiento)
print(f"Perplejidad Suavizada con Interpolación: {perplejidad_interpolada:.4f}")

perplejidad_backoff = calcular_perplejidad(modelo_backoff, corpus_entrenamiento)
print(f"Perplejidad Suavizada con Backoff: {perplejidad_backoff:.4f}")

def generar_oracion(modelo: ModeloNGrama, max_longitud: int = 100) -> str:
    if modelo.n == 1:
        contexto_ocurrencia = []
    else:
        contexto_ocurrencia = ['<s>'] * (modelo.n - 1)

    oracion = contexto_ocurrencia.copy()

    for _ in range(max_longitud):
        contexto = tuple(oracion[-(modelo.n - 1):]) if modelo.n > 1 else tuple()
        palabra_siguiente = predecir_siguiente_palabra(modelo, contexto)

        if palabra_siguiente == '</s>':
            break

        oracion.append(palabra_siguiente)

    return ' '.join(oracion[(modelo.n - 1):])

def predecir_siguiente_palabra(modelo: ModeloNGrama, contexto: Tuple[str, ...]) -> str:
    ngramas_probables = [(ngrama[-1], prob) for ngrama, prob in modelo.cuenta_ngrama.items() if ngrama[:-1] == contexto]

    if not ngramas_probables:
        return '</s>'

    palabras, probabilidades = zip(*ngramas_probables)

    suma_probabilidades = sum(probabilidades)
    probabilidades_normalizadas = [prob / suma_probabilidades for prob in probabilidades]

    palabra_siguiente = random.choices(palabras, probabilidades_normalizadas)[0]

    return palabra_siguiente

print("Oración generada con Unigrama:", generar_oracion(modelo_unigrama))
print("Oración generada con Bigrama:", generar_oracion(modelo_bigrama))
print("Oración generada con Trigrama:", generar_oracion(modelo_trigrama))

def generar_oracion_backoff(modelo: ModeloBackoffNGrama, max_longitud: int = 100) -> str:
    if modelo.modelo_trigrama.n == 1:
        contexto_ocurrencia = []
    else:
        contexto_ocurrencia = ['<s>'] * (modelo.modelo_trigrama.n - 1)

    oracion = contexto_ocurrencia.copy()

    for _ in range(max_longitud):
        contexto = tuple(oracion[-(modelo.modelo_trigrama.n - 1):]) if modelo.modelo_trigrama.n > 1 else tuple()
        palabra_siguiente = predecir_siguiente_palabra_backoff(modelo, contexto)

        if palabra_siguiente == '</s>':
            break

        oracion.append(palabra_siguiente)

    return ' '.join(oracion[(modelo.modelo_trigrama.n - 1):])

def predecir_siguiente_palabra_backoff(modelo: ModeloBackoffNGrama, contexto: Tuple[str, ...]) -> str:
    ngramas_probables = [(ngrama[-1], modelo.obtener_prob_ngram(ngrama))
                         for ngrama in modelo.modelo_trigrama.cuenta_ngrama.keys()
                         if ngrama[:-1] == contexto]

    if not ngramas_probables:
        return '</s>'

    palabras, probabilidades = zip(*ngramas_probables)
    suma_probabilidades = sum(probabilidades)
    probabilidades_normalizadas = [prob / suma_probabilidades for prob in probabilidades]
    palabra_siguiente = random.choices(palabras, probabilidades_normalizadas)[0]

    return palabra_siguiente

def generar_oracion_interpolado(modelo: ModeloInterpoladoNGrama, max_longitud: int = 100) -> str:
    if modelo.modelo_trigrama.n == 1:
        contexto_ocurrencia = []
    else:
        contexto_ocurrencia = ['<s>'] * (modelo.modelo_trigrama.n - 1)

    oracion = contexto_ocurrencia.copy()

    for _ in range(max_longitud):
        contexto = tuple(oracion[-(modelo.modelo_trigrama.n - 1):]) if modelo.modelo_trigrama.n > 1 else tuple()
        palabra_siguiente = predecir_siguiente_palabra_interpolado(modelo, contexto)

        if palabra_siguiente == '</s>':
            break

        oracion.append(palabra_siguiente)

    return ' '.join(oracion[(modelo.modelo_trigrama.n - 1):])

def predecir_siguiente_palabra_interpolado(modelo: ModeloInterpoladoNGrama, contexto: Tuple[str, ...]) -> str:
    ngramas_probables = [(ngrama[-1], modelo.obtener_prob_interpolada(ngrama))
                         for ngrama in modelo.modelo_trigrama.cuenta_ngrama.keys()
                         if ngrama[:-1] == contexto]

    if not ngramas_probables:
        return '</s>'

    palabras, probabilidades = zip(*ngramas_probables)
    suma_probabilidades = sum(probabilidades)
    probabilidades_normalizadas = [prob / suma_probabilidades for prob in probabilidades]
    palabra_siguiente = random.choices(palabras, probabilidades_normalizadas)[0]

    return palabra_siguiente

print("Oración generada con Backoff:", generar_oracion_backoff(modelo_backoff))
print("Oración generada con Interpolación:", generar_oracion_interpolado(modelo_interpolado))
