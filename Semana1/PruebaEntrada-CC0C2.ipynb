{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37e5cdff",
   "metadata": {},
   "source": [
    "### Prueba de entrada\n",
    "\n",
    "Un pipeline de NLP es una secuencia estructurada de pasos que permite a una computadora procesar y analizar texto de manera sistemática, extrayendo información significativa. Cada paso en el pipeline se enfoca en una tarea específica del procesamiento del lenguaje, y juntos forman un sistema completo para entender y manipular el lenguaje natural.\n",
    "\n",
    "Los pasos fundamentales en un pipeline de NLP incluyen:\n",
    "\n",
    "1. **Segmentación de oraciones:** Dividir el texto en oraciones individuales, lo cual facilita el procesamiento posterior al tratar cada oración como una unidad de análisis.\n",
    "2. **Tokenización:** Separar las oraciones en palabras o tokens, lo que permite el análisis detallado de cada unidad de texto.\n",
    "3. **Predicción de partes gramaticales (POS):** Identificar la categoría gramatical de cada token (como sustantivo, verbo, adjetivo), lo cual ayuda a comprender la estructura gramatical de las oraciones.\n",
    "4. **Lematización:** Reducir las palabras a su forma básica o lema, para asegurar que diferentes formas de una palabra se traten como una misma entidad.\n",
    "5. **Identificación de stopwords:** Marcar palabras comunes y de poca relevancia (como \"and\", \"the\"), que pueden ser filtradas para reducir el ruido en el análisis.\n",
    "6. **Análisis de dependencias:** Entender las relaciones gramaticales entre las palabras de una oración, como identificar qué palabras dependen de otras.\n",
    "7. **Reconocimiento de entidades nombradas (NER):** Detectar y etiquetar nombres de personas, lugares y organizaciones, para extraer información específica del texto.\n",
    "8. **Resolución de coreferencia:** Determinar a qué entidad se refieren los pronombres en el texto, para entender mejor la referencia de entidades en el contexto.\n",
    "\n",
    "Cada uno de estos pasos contribuye a la extracción de información significativa de un texto, permitiendo a una computadora \"entender\" el contenido de manera más efectiva. Este proceso es fundamental en muchas aplicaciones de NLP, como la traducción automática, la generación de texto, y el análisis de sentimientos.\n",
    "\n",
    "**Nota:** Este proyecto deberá ser subido a tu repositorio personal a más tardar el 7 de septiembre.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ba7450",
   "metadata": {},
   "source": [
    "**Pregunta**\n",
    "\n",
    "Desarrolla un pipeline simplificado de NLP que incluya tres componentes clave: tokenización usando expresiones regulares (Regex), codificación Byte Pair Encoding (BPE) para la compresión de tokens, y cálculo de distancia de edición para comparar la similitud entre tokens.\n",
    "\n",
    "**Instrucciones:**\n",
    "\n",
    "1. **Tokenización con regex:**\n",
    "   - Implementa un tokenizador utilizando expresiones regulares. El tokenizador debe ser capaz de separar el texto en palabras, respetando la puntuación como tokens independientes.\n",
    "   - Por ejemplo, usando el texto: `\"London is the capital and most populous city of England and the United Kingdom.\"`, el resultado esperado sería:\n",
    "     ```\n",
    "     [\"London\", \"is\", \"the\", \"capital\", \"and\", \"most\", \"populous\", \"city\", \"of\", \"England\", \"and\", \"the\", \"United\", \"Kingdom\", \".\"]\n",
    "     ```\n",
    "\n",
    "2. **Aplicación de byte pair encoding (BPE):**\n",
    "   - Implementa el algoritmo de Byte Pair Encoding para comprimir la representación de los tokens.\n",
    "   - Aplica BPE sobre el conjunto de tokens obtenido en el paso anterior y muestra cómo el vocabulario se reduce mediante la combinación de pares de caracteres más frecuentes.\n",
    "   - Evalúa cómo BPE afecta el tamaño del vocabulario y la representación de palabras raras.\n",
    "\n",
    "3. **Cálculo de distancia de edición:**\n",
    "   - Implementa un algoritmo de distancia de edición (por ejemplo, la distancia de Levenshtein) para comparar la similitud entre diferentes tokens en el texto.\n",
    "   - Utiliza la distancia de edición para identificar palabras similares dentro del texto tokenizado. Por ejemplo, compara palabras como `\"London\"` y `\"Londinium\"` y analiza su similitud.\n",
    "\n",
    "4. **Integración en un pipeline:**\n",
    "   - Integra los tres componentes anteriores en un pipeline simple que procese un texto de entrada desde la tokenización hasta la evaluación de similitudes.\n",
    "   - Evalúa el desempeño del pipeline en un texto de prueba, y discute posibles mejoras o ajustes.\n",
    "\n",
    "**Criterios de evaluación:**\n",
    "\n",
    "- Correctitud en la implementación de cada componente del pipeline.\n",
    "- Eficiencia en la aplicación del algoritmo BPE y en la reducción del vocabulario.\n",
    "- Precisión en el cálculo de la distancia de edición y en la identificación de palabras similares.\n",
    "- Calidad del código (documentación, modularidad, legibilidad) y análisis crítico de los resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f88b0986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['London', 'is', 'the', 'capital', 'and', 'most', 'populous', 'city', 'of', 'England', 'and', 'the', 'United', 'Kingdom', '.']\n",
      "BPE vocabulario: Counter({'the': 2, 'and': 2, 'London': 1, 'is': 1, 'capital': 1, 'most': 1, 'populous': 1, 'city': 1, 'of': 1, 'England': 1, 'United': 1, 'Kingdom': 1, '.': 1})\n",
      "Distancia entre 'London' y 'Londinium': 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "#Regex para separar palabras y puntuaciones\n",
    "def tokenizar(texto):\n",
    "    \n",
    "    tokens = re.findall(r'\\w+|[^\\w\\s]', texto)\n",
    "    return tokens\n",
    "\n",
    "#Genera un vocabulario con frecuencias de pares de tokens\n",
    "def get_vocab(tokens):\n",
    "    vocab = Counter(tokens)\n",
    "    return vocab\n",
    "\n",
    "#Obtiene las frecuencias de pares de caracteres adyacentes\n",
    "def frecuencia(vocab):   \n",
    "    parejas = defaultdict(int)\n",
    "    for palabra, freq in vocab.items():\n",
    "        aux = palabra.split()\n",
    "        for i in range(len(aux)-1):\n",
    "            parejas[aux[i], aux[i+1]] += freq\n",
    "    return parejas\n",
    "\n",
    "#Combina el par más frecuente en el vocabulario\n",
    "def merge(pareja, vocab):\n",
    "    new_vocab = Counter()\n",
    "    aux = re.escape(' '.join(pareja))\n",
    "    p = re.compile(r'(?<!\\S)' + aux + r'(?!\\S)')\n",
    "    for palabra in vocab:\n",
    "        new_palabra = p.sub(''.join(pareja), palabra)\n",
    "        new_vocab[new_palabra] = vocab[palabra]\n",
    "    return new_vocab\n",
    "\n",
    "#Aplica byte pair encoding a los tokens dados\n",
    "def bpe(tokens, num_merges=10):\n",
    "    vocab = get_vocab(tokens)\n",
    "    for i in range(num_merges):\n",
    "        parejas = frecuencia(vocab)\n",
    "        if not parejas:\n",
    "            break\n",
    "        mejor = max(parejas, key=parejas.get)\n",
    "        vocab = merge(mejor, vocab)\n",
    "    return vocab\n",
    "\n",
    "#Calcula la distancia de Levenshtein entre dos cadenas\n",
    "def levenshtein(a, b):\n",
    "    if not a:\n",
    "        return len(b)\n",
    "    if not b:\n",
    "        return len(a)\n",
    "    if a[0] == b[0]:\n",
    "        return levenshtein(a[1:], b[1:])\n",
    "    return 1 + min(levenshtein(a[1:], b), levenshtein(a, b[1:]), levenshtein(a[1:], b[1:]))\n",
    "\n",
    "def nlp_pipeline(texto):\n",
    "    #Tokenización\n",
    "    tokens = tokenizar(texto)\n",
    "    \n",
    "    #Aplicación de BPE\n",
    "    bpe_vocab = bpe(tokens)\n",
    "    \n",
    "    #Cálculo de distancia de edición entre dos palabras ejemplo\n",
    "    distancia = levenshtein('London', 'Londinium')\n",
    "    return tokens, bpe_vocab, distancia\n",
    "\n",
    "#texto de prueba\n",
    "texto = \"London is the capital and most populous city of England and the United Kingdom.\"\n",
    "tokens, bpe_vocab, distancia = nlp_pipeline(texto)\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"BPE vocabulario:\", bpe_vocab)\n",
    "print(\"Distancia entre 'London' y 'Londinium':\", distancia)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
